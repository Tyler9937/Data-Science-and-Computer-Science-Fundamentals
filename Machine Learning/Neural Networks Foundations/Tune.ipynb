{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import needed libaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features array shape:  (10000, 50)\n",
      "Target array length:  10000\n"
     ]
    }
   ],
   "source": [
    "# Example modified from:\n",
    "# https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/\n",
    "\n",
    "# Define the number of features\n",
    "num_features=50\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "# binary classification (two classes)\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = num_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 42)\n",
    "\n",
    "# Verify the size of the features and target\n",
    "print(\"Features array shape: \", features.shape)\n",
    "print(\"Target array length: \", len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a compiled network\n",
    "def make_network(optimizer='adam'):\n",
    "\n",
    "    # Instantiate a sequential model\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add an input layer (shape=number of features)\n",
    "    network.add(layers.Dense(units=8, activation='relu', input_shape=(num_features,)))\n",
    "\n",
    "    # Add a hidden layer with 8 neurons\n",
    "    network.add(layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "    # Add an output layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=['accuracy']) # Accuracy performance metric\n",
    "\n",
    "    # Return compiled network\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\AppData\\Local\\Temp/ipykernel_5180/2594605819.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  neural_network = KerasClassifier(build_fn=make_network, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "neural_network = KerasClassifier(build_fn=make_network, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter space over which to search\n",
    "epochs = [10]\n",
    "batches = [4]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "\n",
    "# Make a dictionary of the parameters\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "grid = GridSearchCV(estimator=neural_network, cv=5, param_grid=hyperparameters)\n",
    "grid_result = grid.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'epochs': 10, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the best parameters\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameter Tuning with Tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of features\n",
    "num_features=50\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "# binary classification (two classes)\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = num_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       random_state = 42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters and values\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Write the function to create the logs\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adapt TensorFlow runs to log hyperparameters and metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function to create the model with the\n",
    "# specified hyperparameter tuning\n",
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "# Run with 1 epoch to speed things up for demo purposes\n",
    "  model.fit(x_train, y_train, epochs=1) \n",
    "  _, accuracy = model.evaluate(x_test, y_test)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log an hparams summary with the hyperparameters and final accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start runs and log them all under one parent directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9439 - accuracy: 0.3533\n",
      "79/79 [==============================] - 0s 853us/step - loss: 1.1933 - accuracy: 0.70920s - loss: 1.1879 - accuracy: 0.70\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.5377 - accuracy: 0.5105\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8750 - accuracy: 0.7536\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 2.0043 - accuracy: 0.3536\n",
      "79/79 [==============================] - 0s 942us/step - loss: 1.2532 - accuracy: 0.5600\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.5987 - accuracy: 0.4339\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.9334 - accuracy: 0.6712\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.4847 - accuracy: 0.4999\n",
      "79/79 [==============================] - 0s 868us/step - loss: 0.7453 - accuracy: 0.7388\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.1014 - accuracy: 0.6645\n",
      "79/79 [==============================] - 0s 895us/step - loss: 0.6234 - accuracy: 0.7904\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.5576 - accuracy: 0.4465\n",
      "79/79 [==============================] - 0s 868us/step - loss: 0.7564 - accuracy: 0.7396\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.4241 - accuracy: 0.4835\n",
      "79/79 [==============================] - 0s 898us/step - loss: 0.8101 - accuracy: 0.6944\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the results in TensorBoard's HParams plugin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7176), started 0:09:55 ago. (Use '!kill 7176' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b3b4cd11f329aa5f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b3b4cd11f329aa5f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b8e1b44fef6f769bdcd84daa9e6bcf329c54142ae85aa21700236386f9708da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
